{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/giandomenico/Documents/SAPIENZA/Papers/PBL_Failure Hazard/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file(\"crolli_2022_3857_membro.shp\").set_index('id')\n",
    "data['Data'] = pd.to_datetime(data['Data'])\n",
    "data = data.sort_values(by='Data')\n",
    "data['Litologia'] = data['Litologia'].replace({'Marna': 'Marl','marna': 'Marl', 'Arenaria':'Sandstone', 'arenaria':'Sandstone'})\n",
    "\n",
    "# Select from May 2022 to May 2023\n",
    "data = data.set_index(['Data'])\n",
    "data = data.loc['2022-05-01': '2023-05-31']\n",
    "time_interval = (data.index.max() - data.index.min()).days+1\n",
    "areas = data['area_m'].values\n",
    "times = data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_pml = 14356\n",
    "area_pml_marl = round(area_pml*0.3, 1)\n",
    "area_pml_sandstone = round(area_pml*0.7, 1)\n",
    "\n",
    "area_pa = 15444\n",
    "area_pa_marl = round(area_pa*0.5, 1)\n",
    "area_pa_sandstone = round(area_pa*0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Descriptive Statistics on Rockfall events.\n",
    "stat = data.describe()\n",
    "stat_lito = data.groupby('Litologia')['area_m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAMS\n",
    "# create unique value for each group\n",
    "rf_mag_giu_lug22['group'] = 1\n",
    "rf_ago_set_ott22['group'] = 2\n",
    "rf_nov_dic_gen2223['group'] = 3\n",
    "rf_fb_mar_apr_mag23['group'] = 4\n",
    "# concat the groups\n",
    "rf_groups_months = pd.concat([rf_mag_giu_lug22, rf_ago_set_ott22, rf_nov_dic_gen2223, rf_fb_mar_apr_mag23], ignore_index=True)\n",
    "# rf_groups_months.to_file(\"crolli_grouped_months.gpkg\", driver='GPKG')\n",
    "\n",
    "#%% plot hist stacked by groups\n",
    "# Define the color palette\n",
    "colors = ['#648FFF', '#DC267F', '#FE6100', '#FFB000']\n",
    "# Define the legend labels\n",
    "legend_labels = ['Feb\\'23-May\\'23', 'Nov\\'22-Jan\\'23','Aug\\'22-Oct\\'22', 'May\\'22-July\\'22']\n",
    "\n",
    "plt.figure(figsize=(7,5), dpi=600, facecolor='w', edgecolor='black')\n",
    "sns.histplot(data=rf_groups_months, x='area_m', hue='group', stat='count',\n",
    "             shrink=.8, multiple='stack', element='bars', bins=15, binwidth=.5, fill=1,\n",
    "             log_scale=(True, False), cumulative=0, kde=0,\n",
    "               palette=colors, zorder=2\n",
    "             )\n",
    "\n",
    "# inverting the x-axis\n",
    "# plt.gca().invert_xaxis()\n",
    "# plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xlabel('Area ($\\mathrm{m^{2}}$)', fontsize=14)\n",
    "plt.ylabel('Rockfalls Count', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "lw = 1.4\n",
    "plt.gca().spines['top'].set_linewidth(lw)\n",
    "plt.gca().spines['bottom'].set_linewidth(lw)\n",
    "plt.gca().spines['left'].set_linewidth(lw)\n",
    "plt.gca().spines['right'].set_linewidth(lw)\n",
    "plt.grid(axis='y', color='gray', alpha=0.15, zorder=1, lw=1)\n",
    "\n",
    "# Change the legend labels\n",
    "plt.legend(labels=legend_labels, fontsize=14, frameon=0)\n",
    "\n",
    "# plt.savefig(\"figures/rf_Hist_temporal_occurrence.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Frequency-Magnitude Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hazard_curve(data, col, time_interval, N=33, title='Frequency - Magnitude Relations'):\n",
    "    V_max = data[col].max()+1\n",
    "    sorted_vol = np.sort(data[col].values)[::-1]\n",
    "    cumulative_frequencies = np.cumsum(sorted_vol < V_max)\n",
    "    total_area_hm2 = 29800 / 10000\n",
    "    total_time_years = time_interval /365\n",
    "    normalized_cumulative_frequencies = cumulative_frequencies / (total_area_hm2 * total_time_years)\n",
    "    \n",
    "    # Slice to fit power law\n",
    "    V_SEL = sorted_vol[:-N]\n",
    "    freq_SEL = normalized_cumulative_frequencies[:-N]\n",
    "    def power_law(x, a, b):\n",
    "        return a * np.power(x, b)\n",
    "    \n",
    "    # Fit the power-law curve\n",
    "    params, covariance = curve_fit(power_law, V_SEL, freq_SEL)\n",
    "    a, b = params\n",
    "    print(f'Fitted Parameters: a = {a:.2f}, b = {b:.2f}')\n",
    "    # Display the equation of the fitted curve\n",
    "    equation = f'λ$_{{st}}$ = {a:.2f} * A^{b:.2f}'\n",
    "    print(f'Equation: {equation}')\n",
    "    # Compute R-squared value\n",
    "    predicted_cumulative_frequencies = power_law(V_SEL, a, b)\n",
    "    r_squared = r2_score(freq_SEL, predicted_cumulative_frequencies)\n",
    "    print(f'R-squared: {r_squared}')\n",
    "    # OVERALL FAILURE FREQUENCY\n",
    "    failure_frequency = len(data) / time_interval\n",
    "    # n = 1\n",
    "    # Pf = ((failure_frequency**n) / np.math.factorial(n) ) * math.exp(-1*failure_frequency)\n",
    "    Pf = 1 - math.exp(-1*failure_frequency)\n",
    "    print(f\"The failure probability is: {Pf:.2f}\")\n",
    "    \n",
    "    # Plot the Fitted Curve\n",
    "    plt.figure(figsize=(7,5), dpi=600)\n",
    "    plt.scatter(sorted_vol, normalized_cumulative_frequencies, marker='o', color='k', alpha=0.5, label='Rockfall Events')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Area ($\\mathrm{m^{2}}$)', fontsize=11)\n",
    "    plt.ylabel('Normalised Cumulative Frequency \\n($\\mathrm{hm^{-2} \\cdot year^{-1}}$)', fontsize=11)\n",
    "    plt.title(title, fontsize=13)\n",
    "\n",
    "    x_fit = np.logspace(np.log10(min(V_SEL)), np.log10(max(V_SEL)), 100)\n",
    "    y_fit = power_law(x_fit, a, b)\n",
    "    plt.plot(x_fit, y_fit, color='r', label='Power-Law Fit', lw=2, ls='dashed')\n",
    "    \n",
    "\n",
    "    # Annotate the plot with the equation and R-squared value\n",
    "    equation_text = f'{equation}\\nR-squared: {r_squared:.2f}\\nPf: {Pf:.2f}'\n",
    "    plt.annotate(equation_text, xy=(0.1, 0.1), xycoords='axes fraction', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white'))\n",
    "\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", lw=0.4)\n",
    "\n",
    "    plt.legend(fontsize=11)\n",
    "    # plt.savefig(f'figures/{title}.png', dpi=600)\n",
    "    # plt.savefig(f'figures/{title}.svg', format='SVG')\n",
    "    plt.show()\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPARE HAZARD CURVES\n",
    "def compare_hazard_curve(data, col, time_interval, by='Membro', total=False):\n",
    "    # create list with sectors\n",
    "    sectors = np.unique(data[by]).tolist()\n",
    "    # sectors.append('Total')\n",
    "    total_time_years = time_interval / 365  # Convert from days to years\n",
    "    # Set N\n",
    "    N = 25\n",
    "    plt.figure(figsize=(7,5), dpi=600)\n",
    "    # iterate over the sectors\n",
    "    for s in sectors:\n",
    "        # crete subset of data\n",
    "        if total:\n",
    "            df = data\n",
    "        else:\n",
    "            df = data[data[by] == s]\n",
    "        # By Lithology\n",
    "        if total:\n",
    "            color, fit_color, label, xy = 'k', 'r','Rockfall Events', (0.25, 0.15)\n",
    "            # Define the total area\n",
    "            total_area_hm2 = 29800 / 10000  # Convert from square meters to hectometers squared\n",
    "        elif s == 'Marl':\n",
    "            color, fit_color, label, xy = '#0C7BDC', '#0C7BDC','Rockfalls in Marls', (0.25,0.15)\n",
    "            total_area_hm2 = 12028.8 / 10000\n",
    "        elif s == 'Sandstone':\n",
    "            color, fit_color, label, xy = '#FFC20A', '#FFC20A','Rockfalls in Sandstone', (0.65,0.5)\n",
    "            total_area_hm2 = 17771.2 / 10000\n",
    "        # By Formation\n",
    "        elif s == 'pa':\n",
    "            color, fit_color, label, xy = '#0C7BDC', '#0C7BDC','Rockfalls from PA', (0.25,0.15)\n",
    "            total_area_hm2 = 15444 / 10000\n",
    "        elif s == 'pml':\n",
    "            color, fit_color, label, xy = '#FFC20A', '#FFC20A','Rockfalls from PML', (0.65,0.5)\n",
    "            total_area_hm2 = 14356 / 10000\n",
    "        else: pass\n",
    "        # Compute volumes and frequencies\n",
    "        V_max = df[col].max()+1\n",
    "        sorted_vol = np.sort(df[col].values)[::-1]\n",
    "        cumulative_frequencies = np.cumsum(sorted_vol < V_max)\n",
    "        normalized_cumulative_frequencies = cumulative_frequencies / (total_area_hm2 * total_time_years)\n",
    "        # Slice to fit power law\n",
    "        V_SEL = sorted_vol[:-N]\n",
    "        freq_SEL = normalized_cumulative_frequencies[:-N]\n",
    "        def power_law(x, a, b):\n",
    "            return a * (x ** b)\n",
    "        # Fit the power-law curve\n",
    "        params, covariance = curve_fit(power_law, V_SEL, freq_SEL)\n",
    "        a, b = params\n",
    "        print(f'Fitted Parameters for {s}: a = {a}, b = {b}')\n",
    "        # Display the equation of the fitted curve\n",
    "        equation = f'λ$_{{st}}$ = {a:.2f} * A^{b:.2f}'\n",
    "        print(f'Equation for {s}: {equation}')\n",
    "        # Compute R-squared value\n",
    "        predicted_cumulative_frequencies = power_law(V_SEL, a, b)\n",
    "        r_squared = r2_score(freq_SEL, predicted_cumulative_frequencies)\n",
    "        print(f'R-squared for {s}: {r_squared}')\n",
    "        # OVERALL FAILURE FREQUENCY\n",
    "        failure_frequency = len(df) / time_interval\n",
    "        # n = 1\n",
    "        # Pf = ((failure_frequency**n) / np.math.factorial(n) ) * math.exp(-1*failure_frequency)\n",
    "        Pf = 1 - math.exp(-1*failure_frequency)\n",
    "        print(f\"The failure probability of {s} is: {Pf:.2f}\")\n",
    "    \n",
    "        # Plot the Fitted Curve\n",
    "        \n",
    "        plt.scatter(sorted_vol, normalized_cumulative_frequencies, marker='o', color=color, edgecolor='k', alpha=0.5, label=label)\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Area ($\\mathrm{m^{2}}$)', fontsize=11)\n",
    "        plt.ylabel('Normalised Cumulative Frequency\\n($\\mathrm{hm^{-2} \\cdot year^{-1}}$)', fontsize=11)\n",
    "        # plt.title('Frequency - Magnitude Relations', fontsize=13)\n",
    "    \n",
    "        x_fit = np.logspace(np.log10(min(V_SEL)), np.log10(max(V_SEL)), 50)\n",
    "        y_fit = power_law(x_fit, a, b)\n",
    "        plt.plot(x_fit, y_fit, color=fit_color, label='Power-Law Fit', lw=3, ls='dashed')\n",
    "        \n",
    "        # Annotate the plot with the equation and R-squared value\n",
    "        equation_text = f'{equation}\\nR-squared: {r_squared:.2f}\\nP$_{{f}}$: {Pf:.2f}'\n",
    "        plt.annotate(equation_text, xy=xy, xycoords='axes fraction', fontsize=10.5, \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=fit_color, facecolor='white', lw=.5))\n",
    "    \n",
    "    plt.grid(which='both', axis='both', lw=0.2)\n",
    "    plt.legend(fontsize=11)\n",
    "    # plt.savefig(f'figures/H_Curve_by_{by}.png')\n",
    "    # plt.savefig(f'figures/H_Curve_by_{by}.svg', format='SVG', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_curve(data, col='area_m', time_interval=time_interval, N=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_hazard_curve(data, 'area_m', time_interval, by='Membro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_hazard_curve(data, 'area_m', time_interval, by='Litologia')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
